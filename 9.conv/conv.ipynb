{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb92975f-28d5-4f7d-ab6a-ff852a0359e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df9305c1-cab5-4bb1-a147-7cfe19813643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(arr : torch.Tensor, k : torch.Tensor, stride = 1) -> torch.Tensor:\n",
    "        assert len(arr.shape) == len(k.shape) == 2\n",
    "        assert arr.shape[0] >= k.shape[0] and arr.shape[1] >= k.shape[1]\n",
    "\n",
    "        m = int((arr.shape[0] - k.shape[0]) / stride + 1)\n",
    "        n = int((arr.shape[1] - k.shape[1]) / stride + 1)\n",
    "\n",
    "        out = torch.zeros((m, n))\n",
    "        print(out.shape)\n",
    "\n",
    "        for i in range(m):\n",
    "                for j in range(n):\n",
    "                        start_i = i * stride\n",
    "                        end_i = i * stride + k.shape[0]\n",
    "                        start_j = j * stride\n",
    "                        end_j = j * stride + k.shape[0]\n",
    "                        out[i, j] = (arr[start_i : end_i, start_j : end_j] * k).sum()\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49a3a184-61ce-46b3-b243-1eaab0ca9a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8]]) tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "arr = torch.stack([torch.arange(9)] * 9)\n",
    "k = torch.ones((3, 3))\n",
    "print(arr, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af58e33a-54e8-41d8-a839-dc84693f95ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 9., 18., 27., 36., 45., 54., 63.],\n",
       "        [ 9., 18., 27., 36., 45., 54., 63.],\n",
       "        [ 9., 18., 27., 36., 45., 54., 63.],\n",
       "        [ 9., 18., 27., 36., 45., 54., 63.],\n",
       "        [ 9., 18., 27., 36., 45., 54., 63.],\n",
       "        [ 9., 18., 27., 36., 45., 54., 63.],\n",
       "        [ 9., 18., 27., 36., 45., 54., 63.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(arr, k, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "247fc258-662e-42b8-9795-5ad61146ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "        def __init__(self, size : tuple):\n",
    "                super().__init__()\n",
    "                self.weight = nn.Parameter(torch.rand(size))\n",
    "                self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        def forward(self, X):\n",
    "                return conv2d(X, self.weight) + self.bias\n",
    "\n",
    "net = Net((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05b8b5e5-4df5-43f9-abbe-c10158c100c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.7082,  9.7866, 14.8649, 19.9433, 25.0216, 30.0999, 35.1783],\n",
       "        [ 4.7082,  9.7866, 14.8649, 19.9433, 25.0216, 30.0999, 35.1783],\n",
       "        [ 4.7082,  9.7866, 14.8649, 19.9433, 25.0216, 30.0999, 35.1783],\n",
       "        [ 4.7082,  9.7866, 14.8649, 19.9433, 25.0216, 30.0999, 35.1783],\n",
       "        [ 4.7082,  9.7866, 14.8649, 19.9433, 25.0216, 30.0999, 35.1783],\n",
       "        [ 4.7082,  9.7866, 14.8649, 19.9433, 25.0216, 30.0999, 35.1783],\n",
       "        [ 4.7082,  9.7866, 14.8649, 19.9433, 25.0216, 30.0999, 35.1783]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6818e65a-888c-48fe-8120-b44043b3b898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 6, 8]) torch.Size([1, 1, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1, 1, 6, 8))\n",
    "Y = torch.rand((1, 1, 6, 7))\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6184ee8-729f-454b-aebb-1b7907e9c772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 62.585357666015625\n",
      "epoch 2 loss 24.129060745239258\n",
      "epoch 4 loss 10.812389373779297\n",
      "epoch 6 loss 6.201056957244873\n",
      "epoch 8 loss 4.604224681854248\n"
     ]
    }
   ],
   "source": [
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "for i in range(10):\n",
    "        conv.zero_grad()\n",
    "        Y_hat = conv(X)\n",
    "        loss = (Y_hat - Y) ** 2\n",
    "        \n",
    "        loss.sum().backward()\n",
    "        conv.weight.data[:] -= 3e-2 * conv.weight.grad\n",
    "\n",
    "        if i % 2 == 0:\n",
    "                print(f\"epoch {i} loss {loss.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffc08774-17a7-4ba9-8149-b280929975af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48ef3b40-96c5-4664-b12d-4ef5e1755241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size = (3, 5), padding=(0, 1), stride = (3, 4))\n",
    "conv2d(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000e2ed-82ac-40ec-93ee-99d700f7efc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
