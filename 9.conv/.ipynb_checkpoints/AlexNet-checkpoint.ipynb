{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e91781f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 224, 224]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size = 256, resize=(224, 224))\n",
    "X_example, y_example = next(iter(train_iter))\n",
    "print(X_example.shape, y_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac233f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0.weight | Size: torch.Size([96, 1, 11, 11]) | Count: 11616 | torch.float32\n",
      "Layer: 0.bias | Size: torch.Size([96]) | Count: 96 | torch.float32\n",
      "Layer: 3.weight | Size: torch.Size([256, 96, 5, 5]) | Count: 614400 | torch.float32\n",
      "Layer: 3.bias | Size: torch.Size([256]) | Count: 256 | torch.float32\n",
      "Layer: 6.weight | Size: torch.Size([384, 256, 3, 3]) | Count: 884736 | torch.float32\n",
      "Layer: 6.bias | Size: torch.Size([384]) | Count: 384 | torch.float32\n",
      "Layer: 8.weight | Size: torch.Size([384, 384, 3, 3]) | Count: 1327104 | torch.float32\n",
      "Layer: 8.bias | Size: torch.Size([384]) | Count: 384 | torch.float32\n",
      "Layer: 10.weight | Size: torch.Size([256, 384, 3, 3]) | Count: 884736 | torch.float32\n",
      "Layer: 10.bias | Size: torch.Size([256]) | Count: 256 | torch.float32\n",
      "Layer: 14.weight | Size: torch.Size([4096, 6400]) | Count: 26214400 | torch.float32\n",
      "Layer: 14.bias | Size: torch.Size([4096]) | Count: 4096 | torch.float32\n",
      "Layer: 17.weight | Size: torch.Size([4096, 4096]) | Count: 16777216 | torch.float32\n",
      "Layer: 17.bias | Size: torch.Size([4096]) | Count: 4096 | torch.float32\n",
      "Layer: 20.weight | Size: torch.Size([10, 4096]) | Count: 40960 | torch.float32\n",
      "Layer: 20.bias | Size: torch.Size([10]) | Count: 10 | torch.float32\n",
      "Total parameters count: 46764746\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Conv2d(1, 96, kernel_size = 11, stride = 4, padding = 1), nn.ReLU(), \n",
    "                    nn.MaxPool2d(kernel_size = 3, stride = 2), \n",
    "                    nn.Conv2d(96, 256, kernel_size = 5, padding = 2), nn.ReLU(), \n",
    "                    nn.MaxPool2d(kernel_size = 3, stride = 2), \n",
    "                    nn.Conv2d(256, 384, kernel_size = 3, padding = 1), nn.ReLU(), \n",
    "                    nn.Conv2d(384, 384, kernel_size = 3, padding = 1), nn.ReLU(), \n",
    "                    nn.Conv2d(384, 256, kernel_size = 3, padding = 1), nn.ReLU(), \n",
    "                    nn.MaxPool2d(kernel_size = 3, stride = 2), nn.Flatten(),\n",
    "                    nn.Linear(6400, 4096), nn.ReLU(), nn.Dropout(),\n",
    "                    nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(),\n",
    "                    nn.Linear(4096, 10)\n",
    "                   )\n",
    "# 获取参数大小和参数数量\n",
    "total_params = 0\n",
    "for name, param in net.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Count: {param.nelement()} | {param.data.dtype}\")\n",
    "    total_params += param.nelement()\n",
    "\n",
    "print(f\"Total parameters count: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfda1c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d torch.Size([256, 96, 54, 54])\n",
      "ReLU torch.Size([256, 96, 54, 54])\n",
      "MaxPool2d torch.Size([256, 96, 26, 26])\n",
      "Conv2d torch.Size([256, 256, 26, 26])\n",
      "ReLU torch.Size([256, 256, 26, 26])\n",
      "MaxPool2d torch.Size([256, 256, 12, 12])\n",
      "Conv2d torch.Size([256, 384, 12, 12])\n",
      "ReLU torch.Size([256, 384, 12, 12])\n",
      "Conv2d torch.Size([256, 384, 12, 12])\n",
      "ReLU torch.Size([256, 384, 12, 12])\n",
      "Conv2d torch.Size([256, 256, 12, 12])\n",
      "ReLU torch.Size([256, 256, 12, 12])\n",
      "MaxPool2d torch.Size([256, 256, 5, 5])\n",
      "Flatten torch.Size([256, 6400])\n",
      "Linear torch.Size([256, 4096])\n",
      "ReLU torch.Size([256, 4096])\n",
      "Dropout torch.Size([256, 4096])\n",
      "Linear torch.Size([256, 4096])\n",
      "ReLU torch.Size([256, 4096])\n",
      "Dropout torch.Size([256, 4096])\n",
      "Linear torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "for model in net:\n",
    "    X_example = model(X_example)\n",
    "    print(model.__class__.__name__, X_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "209fca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_ch6 in module d2l.torch:\n",
      "\n",
      "train_ch6(net, train_iter, test_iter, num_epochs, lr, device)\n",
      "    Train a model with a GPU (defined in Chapter 6).\n",
      "    \n",
      "    Defined in :numref:`sec_lenet`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(d2l.train_ch6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe2f09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 1.83 GiB total capacity; 14.21 MiB already allocated; 89.75 MiB free; 22.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1278543/3053391212.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ch6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/d2l/torch.py\u001b[0m in \u001b[0;36mtrain_ch6\u001b[0;34m(net, train_iter, test_iter, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training on'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 1.83 GiB total capacity; 14.21 MiB already allocated; 89.75 MiB free; 22.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "d2l.train_ch6(net, train_iter, test_iter, 10, 0.1, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a2de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
