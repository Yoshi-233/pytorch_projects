{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd05b14-150b-47c1-9989-c8a82b88da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "from itertools import chain\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5216e6-3a36-4076-aa59-61ea857cca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_config(path):\n",
    "    \"\"\"Parses the yolo-v3 layer configuration file and returns module definitions\"\"\"\n",
    "    file = open(path, 'r')\n",
    "    lines = file.read().split('\\n')\n",
    "    lines = [x for x in lines if x and not x.startswith('#')]\n",
    "    lines = [x.rstrip().lstrip() for x in lines]  # get rid of fringe whitespaces\n",
    "    module_defs = []\n",
    "    for line in lines:\n",
    "        if line.startswith('['):  # This marks the start of a new block\n",
    "            module_defs.append({})\n",
    "            module_defs[-1]['type'] = line[1:-1].rstrip()\n",
    "            if module_defs[-1]['type'] == 'convolutional':\n",
    "                module_defs[-1]['batch_normalize'] = 0\n",
    "        else:\n",
    "            key, value = line.split(\"=\")\n",
    "            value = value.strip()\n",
    "            module_defs[-1][key.rstrip()] = value.strip()\n",
    "\n",
    "    return module_defs\n",
    "\n",
    "\n",
    "def parse_data_config(path):\n",
    "    \"\"\"Parses the data configuration file\"\"\"\n",
    "    options = dict()\n",
    "    options['gpus'] = '0,1,2,3'\n",
    "    options['num_workers'] = '10'\n",
    "    with open(path, 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line == '' or line.startswith('#'):\n",
    "            continue\n",
    "        key, value = line.split('=')\n",
    "        options[key.strip()] = value.strip()\n",
    "    return options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad8be4c-0cf5-4e8c-9827-662ad2e66c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    \"\"\" nn.Upsample is deprecated \"\"\"\n",
    "\n",
    "    def __init__(self, scale_factor, mode: str = \"nearest\"):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n",
    "        return x\n",
    "\n",
    "\n",
    "class YOLOLayer(nn.Module):\n",
    "    \"\"\"Detection layer\"\"\"\n",
    "\n",
    "    def __init__(self, anchors: List[Tuple[int, int]], num_classes: int, new_coords: bool):\n",
    "        \"\"\"\n",
    "        Create a YOLO layer\n",
    "\n",
    "        :param anchors: List of anchors\n",
    "        :param num_classes: Number of classes\n",
    "        :param new_coords: Whether to use the new coordinate format from YOLO V7\n",
    "        \"\"\"\n",
    "        super(YOLOLayer, self).__init__()\n",
    "        self.num_anchors = len(anchors)\n",
    "        self.num_classes = num_classes\n",
    "        self.new_coords = new_coords\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.no = num_classes + 5  # number of outputs per anchor\n",
    "        self.grid = torch.zeros(1)  # TODO\n",
    "\n",
    "        anchors = torch.tensor(list(chain(*anchors))).float().view(-1, 2)\n",
    "        self.register_buffer('anchors', anchors)\n",
    "        self.register_buffer(\n",
    "            'anchor_grid', anchors.clone().view(1, -1, 1, 1, 2))\n",
    "        self.stride = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor, img_size: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the YOLO layer\n",
    "\n",
    "        :param x: Input tensor\n",
    "        :param img_size: Size of the input image\n",
    "        \"\"\"\n",
    "        stride = img_size // x.size(2)\n",
    "        self.stride = stride\n",
    "        bs, _, ny, nx = x.shape  # x(bs,255,20,20) to x(bs,3,20,20,85)\n",
    "        x = x.view(bs, self.num_anchors, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n",
    "\n",
    "        if not self.training:  # inference\n",
    "            if self.grid.shape[2:4] != x.shape[2:4]:\n",
    "                self.grid = self._make_grid(nx, ny).to(x.device)\n",
    "\n",
    "            if self.new_coords:\n",
    "                x[..., 0:2] = (x[..., 0:2] + self.grid) * stride  # xy\n",
    "                x[..., 2:4] = x[..., 2:4] ** 2 * (4 * self.anchor_grid) # wh\n",
    "            else:\n",
    "                x[..., 0:2] = (x[..., 0:2].sigmoid() + self.grid) * stride  # xy\n",
    "                x[..., 2:4] = torch.exp(x[..., 2:4]) * self.anchor_grid # wh\n",
    "                x[..., 4:] = x[..., 4:].sigmoid() # conf, cls\n",
    "            x = x.view(bs, -1, self.no)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_grid(nx: int = 20, ny: int = 20) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Create a grid of (x, y) coordinates\n",
    "\n",
    "        :param nx: Number of x coordinates\n",
    "        :param ny: Number of y coordinates\n",
    "        \"\"\"\n",
    "        yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)], indexing='ij')\n",
    "        return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()\n",
    "\n",
    "\n",
    "class Darknet(nn.Module):\n",
    "    \"\"\"YOLOv3 object detection model\"\"\"\n",
    "\n",
    "    def __init__(self, config_path):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.module_defs = parse_model_config(config_path)\n",
    "        self.hyperparams, self.module_list = create_modules(self.module_defs)\n",
    "        self.yolo_layers = [layer[0]\n",
    "                            for layer in self.module_list if isinstance(layer[0], YOLOLayer)]\n",
    "        self.seen = 0\n",
    "        self.header_info = np.array([0, 0, 0, self.seen, 0], dtype=np.int32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        img_size = x.size(2)\n",
    "        layer_outputs, yolo_outputs = [], []\n",
    "        for i, (module_def, module) in enumerate(zip(self.module_defs, self.module_list)):\n",
    "            if module_def[\"type\"] in [\"convolutional\", \"upsample\", \"maxpool\"]:\n",
    "                x = module(x)\n",
    "            elif module_def[\"type\"] == \"route\":\n",
    "                combined_outputs = torch.cat([layer_outputs[int(layer_i)] for layer_i in module_def[\"layers\"].split(\",\")], 1)\n",
    "                group_size = combined_outputs.shape[1] // int(module_def.get(\"groups\", 1))\n",
    "                group_id = int(module_def.get(\"group_id\", 0))\n",
    "                x = combined_outputs[:, group_size * group_id : group_size * (group_id + 1)] # Slice groupings used by yolo v4\n",
    "            elif module_def[\"type\"] == \"shortcut\":\n",
    "                layer_i = int(module_def[\"from\"])\n",
    "                x = layer_outputs[-1] + layer_outputs[layer_i]\n",
    "            elif module_def[\"type\"] == \"yolo\":\n",
    "                x = module[0](x, img_size)\n",
    "                yolo_outputs.append(x)\n",
    "            layer_outputs.append(x)\n",
    "        return yolo_outputs if self.training else torch.cat(yolo_outputs, 1)\n",
    "\n",
    "    def load_darknet_weights(self, weights_path):\n",
    "        \"\"\"Parses and loads the weights stored in 'weights_path'\"\"\"\n",
    "\n",
    "        # Open the weights file\n",
    "        with open(weights_path, \"rb\") as f:\n",
    "            # First five are header values\n",
    "            header = np.fromfile(f, dtype=np.int32, count=5)\n",
    "            self.header_info = header  # Needed to write header when saving weights\n",
    "            self.seen = header[3]  # number of images seen during training\n",
    "            weights = np.fromfile(f, dtype=np.float32)  # The rest are weights\n",
    "\n",
    "        # Establish cutoff for loading backbone weights\n",
    "        cutoff = None\n",
    "        # If the weights file has a cutoff, we can find out about it by looking at the filename\n",
    "        # examples: darknet53.conv.74 -> cutoff is 74\n",
    "        filename = os.path.basename(weights_path)\n",
    "        if \".conv.\" in filename:\n",
    "            try:\n",
    "                cutoff = int(filename.split(\".\")[-1])  # use last part of filename\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        ptr = 0\n",
    "        for i, (module_def, module) in enumerate(zip(self.module_defs, self.module_list)):\n",
    "            if i == cutoff:\n",
    "                break\n",
    "            if module_def[\"type\"] == \"convolutional\":\n",
    "                conv_layer = module[0]\n",
    "                if module_def[\"batch_normalize\"]:\n",
    "                    # Load BN bias, weights, running mean and running variance\n",
    "                    bn_layer = module[1]\n",
    "                    num_b = bn_layer.bias.numel()  # Number of biases\n",
    "                    # Bias\n",
    "                    bn_b = torch.from_numpy(\n",
    "                        weights[ptr: ptr + num_b]).view_as(bn_layer.bias)\n",
    "                    bn_layer.bias.data.copy_(bn_b)\n",
    "                    ptr += num_b\n",
    "                    # Weight\n",
    "                    bn_w = torch.from_numpy(\n",
    "                        weights[ptr: ptr + num_b]).view_as(bn_layer.weight)\n",
    "                    bn_layer.weight.data.copy_(bn_w)\n",
    "                    ptr += num_b\n",
    "                    # Running Mean\n",
    "                    bn_rm = torch.from_numpy(\n",
    "                        weights[ptr: ptr + num_b]).view_as(bn_layer.running_mean)\n",
    "                    bn_layer.running_mean.data.copy_(bn_rm)\n",
    "                    ptr += num_b\n",
    "                    # Running Var\n",
    "                    bn_rv = torch.from_numpy(\n",
    "                        weights[ptr: ptr + num_b]).view_as(bn_layer.running_var)\n",
    "                    bn_layer.running_var.data.copy_(bn_rv)\n",
    "                    ptr += num_b\n",
    "                else:\n",
    "                    # Load conv. bias\n",
    "                    num_b = conv_layer.bias.numel()\n",
    "                    conv_b = torch.from_numpy(\n",
    "                        weights[ptr: ptr + num_b]).view_as(conv_layer.bias)\n",
    "                    conv_layer.bias.data.copy_(conv_b)\n",
    "                    ptr += num_b\n",
    "                # Load conv. weights\n",
    "                num_w = conv_layer.weight.numel()\n",
    "                conv_w = torch.from_numpy(\n",
    "                    weights[ptr: ptr + num_w]).view_as(conv_layer.weight)\n",
    "                conv_layer.weight.data.copy_(conv_w)\n",
    "                ptr += num_w\n",
    "\n",
    "    def save_darknet_weights(self, path, cutoff=-1):\n",
    "        \"\"\"\n",
    "            @:param path    - path of the new weights file\n",
    "            @:param cutoff  - save layers between 0 and cutoff (cutoff = -1 -> all are saved)\n",
    "        \"\"\"\n",
    "        fp = open(path, \"wb\")\n",
    "        self.header_info[3] = self.seen\n",
    "        self.header_info.tofile(fp)\n",
    "\n",
    "        # Iterate through layers\n",
    "        for i, (module_def, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n",
    "            if module_def[\"type\"] == \"convolutional\":\n",
    "                conv_layer = module[0]\n",
    "                # If batch norm, load bn first\n",
    "                if module_def[\"batch_normalize\"]:\n",
    "                    bn_layer = module[1]\n",
    "                    bn_layer.bias.data.cpu().numpy().tofile(fp)\n",
    "                    bn_layer.weight.data.cpu().numpy().tofile(fp)\n",
    "                    bn_layer.running_mean.data.cpu().numpy().tofile(fp)\n",
    "                    bn_layer.running_var.data.cpu().numpy().tofile(fp)\n",
    "                # Load conv bias\n",
    "                else:\n",
    "                    conv_layer.bias.data.cpu().numpy().tofile(fp)\n",
    "                # Load conv weights\n",
    "                conv_layer.weight.data.cpu().numpy().tofile(fp)\n",
    "\n",
    "        fp.close()\n",
    "\n",
    "\n",
    "def load_model(model_path, weights_path=None):\n",
    "    \"\"\"Loads the yolo model from file.\n",
    "\n",
    "    :param model_path: Path to model definition file (.cfg)\n",
    "    :type model_path: str\n",
    "    :param weights_path: Path to weights or checkpoint file (.weights or .pth)\n",
    "    :type weights_path: str\n",
    "    :return: Returns model\n",
    "    :rtype: Darknet\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                          else \"cpu\")  # Select device for inference\n",
    "    model = Darknet(model_path).to(device)\n",
    "\n",
    "    model.apply(weights_init_normal)\n",
    "\n",
    "    # If pretrained weights are specified, start from checkpoint or weight file\n",
    "    if weights_path:\n",
    "        if weights_path.endswith(\".pth\"):\n",
    "            # Load checkpoint weights\n",
    "            model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "        else:\n",
    "            # Load darknet weights\n",
    "            model.load_darknet_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c61733-7120-4b6d-9979-149780fb81e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "module_defs = parse_model_config(\"/home/shao/ai_projects/PyTorch-YOLOv3-master/config/yolov3.cfg\")\n",
    "print(len(module_defs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "466003d2-ef27-4797-b955-b0bf5b115e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo_82 [(116, 90), (156, 198), (373, 326)] 80 False\n",
      "yolo_94 [(30, 61), (62, 45), (59, 119)] 80 False\n",
      "yolo_106 [(10, 13), (16, 30), (33, 23)] 80 False\n"
     ]
    }
   ],
   "source": [
    "module_defs = parse_model_config(\"/home/shao/ai_projects/PyTorch-YOLOv3-master/config/yolov3.cfg\")\n",
    "\n",
    "\n",
    "def create_modules(module_defs: List[dict]) -> Tuple[dict, nn.ModuleList]:\n",
    "    \"\"\"\n",
    "    Constructs module list of layer blocks from module configuration in module_defs\n",
    "\n",
    "    :param module_defs: List of dictionaries with module definitions\n",
    "    :return: Hyperparameters and pytorch module list\n",
    "    \"\"\"\n",
    "    hyperparams = module_defs.pop(0)\n",
    "    hyperparams.update({\n",
    "        'batch': int(hyperparams['batch']),\n",
    "        'subdivisions': int(hyperparams['subdivisions']),\n",
    "        'width': int(hyperparams['width']),\n",
    "        'height': int(hyperparams['height']),\n",
    "        'channels': int(hyperparams['channels']),\n",
    "        'optimizer': hyperparams.get('optimizer'),\n",
    "        'momentum': float(hyperparams['momentum']),\n",
    "        'decay': float(hyperparams['decay']),\n",
    "        'learning_rate': float(hyperparams['learning_rate']),\n",
    "        'burn_in': int(hyperparams['burn_in']),\n",
    "        'max_batches': int(hyperparams['max_batches']),\n",
    "        'policy': hyperparams['policy'],\n",
    "        'lr_steps': list(zip(map(int,   hyperparams[\"steps\"].split(\",\")),\n",
    "                             map(float, hyperparams[\"scales\"].split(\",\"))))\n",
    "    })\n",
    "    assert hyperparams[\"height\"] == hyperparams[\"width\"], \\\n",
    "        \"Height and width should be equal! Non square images are padded with zeros.\"\n",
    "    output_filters = [hyperparams[\"channels\"]]\n",
    "    module_list = nn.ModuleList()\n",
    "    for module_i, module_def in enumerate(module_defs):\n",
    "        modules = nn.Sequential()\n",
    "\n",
    "        if module_def[\"type\"] == \"convolutional\":\n",
    "            bn = int(module_def[\"batch_normalize\"])\n",
    "            filters = int(module_def[\"filters\"])\n",
    "            kernel_size = int(module_def[\"size\"])\n",
    "            pad = (kernel_size - 1) // 2\n",
    "            modules.add_module(\n",
    "                f\"conv_{module_i}\",\n",
    "                nn.Conv2d(\n",
    "                    in_channels=output_filters[-1],\n",
    "                    out_channels=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=int(module_def[\"stride\"]),\n",
    "                    padding=pad,\n",
    "                    bias=not bn,\n",
    "                ),\n",
    "            )\n",
    "            if bn:\n",
    "                modules.add_module(f\"batch_norm_{module_i}\",\n",
    "                                   nn.BatchNorm2d(filters, momentum=0.1, eps=1e-5))\n",
    "            if module_def[\"activation\"] == \"leaky\":\n",
    "                modules.add_module(f\"leaky_{module_i}\", nn.LeakyReLU(0.1))\n",
    "            elif module_def[\"activation\"] == \"mish\":\n",
    "                modules.add_module(f\"mish_{module_i}\", nn.Mish())\n",
    "            elif module_def[\"activation\"] == \"logistic\":\n",
    "                modules.add_module(f\"sigmoid_{module_i}\", nn.Sigmoid())\n",
    "            elif module_def[\"activation\"] == \"swish\":\n",
    "                modules.add_module(f\"swish_{module_i}\", nn.SiLU())\n",
    "\n",
    "        elif module_def[\"type\"] == \"maxpool\":\n",
    "            kernel_size = int(module_def[\"size\"])\n",
    "            stride = int(module_def[\"stride\"])\n",
    "            if kernel_size == 2 and stride == 1:\n",
    "                modules.add_module(f\"_debug_padding_{module_i}\", nn.ZeroPad2d((0, 1, 0, 1)))\n",
    "            maxpool = nn.MaxPool2d(kernel_size=kernel_size, stride=stride,\n",
    "                                   padding=int((kernel_size - 1) // 2))\n",
    "            modules.add_module(f\"maxpool_{module_i}\", maxpool)\n",
    "\n",
    "        elif module_def[\"type\"] == \"upsample\":\n",
    "            upsample = Upsample(scale_factor=int(module_def[\"stride\"]), mode=\"nearest\")\n",
    "            modules.add_module(f\"upsample_{module_i}\", upsample)\n",
    "\n",
    "        elif module_def[\"type\"] == \"route\":\n",
    "            layers = [int(x) for x in module_def[\"layers\"].split(\",\")]\n",
    "            # print(module_i, layers)\n",
    "            filters = sum([output_filters[1:][i] for i in layers]) // int(module_def.get(\"groups\", 1))\n",
    "            # print(module_def.get(\"groups\", 1))\n",
    "            modules.add_module(f\"route_{module_i}\", nn.Sequential())\n",
    "\n",
    "        elif module_def[\"type\"] == \"shortcut\":\n",
    "            filters = output_filters[1:][int(module_def[\"from\"])]\n",
    "            modules.add_module(f\"shortcut_{module_i}\", nn.Sequential())\n",
    "\n",
    "        elif module_def[\"type\"] == \"yolo\":\n",
    "            anchor_idxs = [int(x) for x in module_def[\"mask\"].split(\",\")]\n",
    "            # Extract anchors\n",
    "            anchors = [int(x) for x in module_def[\"anchors\"].split(\",\")]\n",
    "            anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]\n",
    "            anchors = [anchors[i] for i in anchor_idxs]\n",
    "            num_classes = int(module_def[\"classes\"])\n",
    "            new_coords = bool(module_def.get(\"new_coords\", False))\n",
    "            # Define detection layer\n",
    "            print(f\"yolo_{module_i}\", anchors, num_classes, new_coords)\n",
    "            yolo_layer = YOLOLayer(anchors, num_classes, new_coords)\n",
    "            modules.add_module(f\"yolo_{module_i}\", yolo_layer)\n",
    "        # Register module list and number of output filters\n",
    "        \n",
    "        # print(filters)\n",
    "        module_list.append(modules)\n",
    "        output_filters.append(filters)\n",
    "        # print(output_filters)\n",
    "\n",
    "    return hyperparams, module_list, output_filters\n",
    "\n",
    "hyperparams, module_list, output_filters = create_modules(module_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0e7c38c-2a30-4181-9d67-8c98521aabdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[116, 90, 156, 198, 373, 326]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [(116, 90), (156, 198), (373, 326)]\n",
    "list(chain(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3895a49-e677-4b8c-b9c2-99b228754fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_0): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 32, 416, 416])\n",
      "Sequential(\n",
      "  (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_1): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 64, 208, 208])\n",
      "Sequential(\n",
      "  (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_2): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 32, 208, 208])\n",
      "Sequential(\n",
      "  (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_3): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 64, 208, 208])\n",
      "Sequential(\n",
      "  (shortcut_4): Sequential()\n",
      ")\n",
      "torch.Size([1, 64, 208, 208])\n",
      "Sequential(\n",
      "  (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_5): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 104, 104])\n",
      "Sequential(\n",
      "  (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_6): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 64, 104, 104])\n",
      "Sequential(\n",
      "  (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_7): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 104, 104])\n",
      "Sequential(\n",
      "  (shortcut_8): Sequential()\n",
      ")\n",
      "torch.Size([1, 128, 104, 104])\n",
      "Sequential(\n",
      "  (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_9): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 64, 104, 104])\n",
      "Sequential(\n",
      "  (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_10): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 104, 104])\n",
      "Sequential(\n",
      "  (shortcut_11): Sequential()\n",
      ")\n",
      "torch.Size([1, 128, 104, 104])\n",
      "Sequential(\n",
      "  (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_12): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_13): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 52, 52])\n",
      "Sequential(\n",
      "  (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_14): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (shortcut_15): Sequential()\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_16): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 52, 52])\n",
      "Sequential(\n",
      "  (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_17): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (shortcut_18): Sequential()\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_19): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 52, 52])\n",
      "Sequential(\n",
      "  (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_20): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (shortcut_21): Sequential()\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_22): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 52, 52])\n",
      "Sequential(\n",
      "  (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_23): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (shortcut_24): Sequential()\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_25): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 52, 52])\n",
      "Sequential(\n",
      "  (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_26): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (shortcut_27): Sequential()\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_28): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 52, 52])\n",
      "Sequential(\n",
      "  (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_29): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (shortcut_30): Sequential()\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_31): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 52, 52])\n",
      "Sequential(\n",
      "  (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_32): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (shortcut_33): Sequential()\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_34): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 128, 52, 52])\n",
      "Sequential(\n",
      "  (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_35): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (shortcut_36): Sequential()\n",
      ")\n",
      "torch.Size([1, 256, 52, 52])\n",
      "Sequential(\n",
      "  (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_37): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_38): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 26, 26])\n",
      "Sequential(\n",
      "  (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_39): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (shortcut_40): Sequential()\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_41): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 26, 26])\n",
      "Sequential(\n",
      "  (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_42): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (shortcut_43): Sequential()\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_44): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 26, 26])\n",
      "Sequential(\n",
      "  (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_45): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (shortcut_46): Sequential()\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_47): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 26, 26])\n",
      "Sequential(\n",
      "  (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_48): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (shortcut_49): Sequential()\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_50): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 26, 26])\n",
      "Sequential(\n",
      "  (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_51): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (shortcut_52): Sequential()\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_53): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 26, 26])\n",
      "Sequential(\n",
      "  (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_54): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (shortcut_55): Sequential()\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_56): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 26, 26])\n",
      "Sequential(\n",
      "  (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_57): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (shortcut_58): Sequential()\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_59): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 256, 26, 26])\n",
      "Sequential(\n",
      "  (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_60): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (shortcut_61): Sequential()\n",
      ")\n",
      "torch.Size([1, 512, 26, 26])\n",
      "Sequential(\n",
      "  (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_62): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_63): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 13, 13])\n",
      "Sequential(\n",
      "  (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_64): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (shortcut_65): Sequential()\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_66): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 13, 13])\n",
      "Sequential(\n",
      "  (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_67): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (shortcut_68): Sequential()\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_69): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 13, 13])\n",
      "Sequential(\n",
      "  (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_70): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (shortcut_71): Sequential()\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_72): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 13, 13])\n",
      "Sequential(\n",
      "  (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_73): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (shortcut_74): Sequential()\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_75): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 13, 13])\n",
      "Sequential(\n",
      "  (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_76): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_77): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 13, 13])\n",
      "Sequential(\n",
      "  (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_78): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_79): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 512, 13, 13])\n",
      "Sequential(\n",
      "  (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_80): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "Sequential(\n",
      "  (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "torch.Size([1, 255, 13, 13])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "YOLOLayer.forward() missing 1 required positional argument: 'img_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m416\u001b[39m, \u001b[38;5;241m416\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m module_list:\n\u001b[0;32m----> 3\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(module)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/automl/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/automl/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/automl/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/automl/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/automl/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: YOLOLayer.forward() missing 1 required positional argument: 'img_size'"
     ]
    }
   ],
   "source": [
    "x = torch.randn((1, 3, 416, 416))\n",
    "for module in module_list:\n",
    "    x = module(x)\n",
    "    print(module)\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "802833d2-dbdc-46ef-8b9a-73c5c6b96eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((1, 255, 13, 13))\n",
    "x.size(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549ba569-0c6a-46d3-a243-21002ce0b1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
