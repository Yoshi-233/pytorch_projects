{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T14:18:30.678985Z",
     "start_time": "2024-08-01T14:18:29.517908Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ae510-7b81-41fb-a6a6-04919a89cb79",
   "metadata": {},
   "source": [
    "### 1. 获取掩码\n",
    "- 在encoder和encoder-decoder的self-attention中，掩码和序列长度有关\n",
    "- 在decoder_layer中的第一层self-attention中，掩码是下三角矩阵\n",
    "- decoder输出掩码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a86e73-20ae-42fd-9bb1-07db652e90d1",
   "metadata": {},
   "source": [
    "#### 1.1 encoder和encoder-decoder的self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bfa5d6e2-7d48-439d-8433-e02522a77f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8823, 0.9150, 0.3829, 0.9593, 0.3904, 0.6009, 0.2566, 0.7936],\n",
      "         [0.9408, 0.1332, 0.9346, 0.5936, 0.8694, 0.5677, 0.7411, 0.4294],\n",
      "         [0.8854, 0.5739, 0.2666, 0.6274, 0.2696, 0.4414, 0.2969, 0.8317],\n",
      "         [0.1053, 0.2695, 0.3588, 0.1994, 0.5472, 0.0062, 0.9516, 0.0753]],\n",
      "\n",
      "        [[0.8860, 0.5832, 0.3376, 0.8090, 0.5779, 0.9040, 0.5547, 0.3423],\n",
      "         [0.6343, 0.3644, 0.7104, 0.9464, 0.7890, 0.2814, 0.7886, 0.5895],\n",
      "         [0.7539, 0.1952, 0.0050, 0.3068, 0.1165, 0.9103, 0.6440, 0.7071],\n",
      "         [0.6581, 0.4913, 0.8913, 0.1447, 0.5315, 0.1587, 0.6542, 0.3278]]]) torch.Size([2, 4, 8])\n",
      "tensor([3, 2]) torch.Size([2])\n",
      "\n",
      "tensor([[0, 1, 2, 3]])\n",
      "tensor([[3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]])\n",
      "tensor([[ True,  True,  True, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True, False, False]])\n",
      "\n",
      "tensor([[3.8917, 3.0907, 3.1170, 1.1894],\n",
      "        [3.0907, 3.9404, 2.5932, 1.8054],\n",
      "        [3.1170, 2.5932, 2.6255, 0.9641],\n",
      "        [1.1894, 1.8054, 0.9641, 1.4628],\n",
      "        [3.4696, 3.1297, 2.5212, 2.2134],\n",
      "        [3.1297, 3.6068, 2.1161, 2.5399],\n",
      "        [2.5212, 2.1161, 2.4576, 1.5005],\n",
      "        [2.2134, 2.5399, 1.5005, 2.3330]]) torch.Size([8, 4])\n",
      "tensor([[ 3.8917e+00,  3.0907e+00,  3.1170e+00, -1.0000e+06],\n",
      "        [ 3.0907e+00,  3.9404e+00,  2.5932e+00, -1.0000e+06],\n",
      "        [ 3.1170e+00,  2.5932e+00,  2.6255e+00, -1.0000e+06],\n",
      "        [ 1.1894e+00,  1.8054e+00,  9.6405e-01, -1.0000e+06],\n",
      "        [ 3.4696e+00,  3.1297e+00, -1.0000e+06, -1.0000e+06],\n",
      "        [ 3.1297e+00,  3.6068e+00, -1.0000e+06, -1.0000e+06],\n",
      "        [ 2.5212e+00,  2.1161e+00, -1.0000e+06, -1.0000e+06],\n",
      "        [ 2.2134e+00,  2.5399e+00, -1.0000e+06, -1.0000e+06]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5236, 0.2350, 0.2413, 0.0000],\n",
       "        [0.2534, 0.5926, 0.1541, 0.0000],\n",
       "        [0.4537, 0.2687, 0.2775, 0.0000],\n",
       "        [0.2740, 0.5073, 0.2187, 0.0000],\n",
       "        [0.5842, 0.4158, 0.0000, 0.0000],\n",
       "        [0.3829, 0.6171, 0.0000, 0.0000],\n",
       "        [0.5999, 0.4001, 0.0000, 0.0000],\n",
       "        [0.4191, 0.5809, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "# encoder/encoder-decoder\n",
    "torch.manual_seed(42)\n",
    "\"\"\"\n",
    "输入矩阵：\n",
    "    batch_size * max_seq_len * dim\n",
    "    batch_size=2, max_seq_len=4, dim=8\n",
    "有效长度矩阵：\n",
    "    batch_size *\n",
    "    batch_size=2\n",
    "\"\"\"\n",
    "X = torch.rand((2, 4, 8))\n",
    "valid_len = torch.randint(1, 5, (2, ))\n",
    "print(X, X.shape)\n",
    "print(valid_len, valid_len.shape)\n",
    "print()\n",
    "\n",
    "max_len = X.shape[1]\n",
    "# 获取长度矩阵\n",
    "print(torch.arange(max_len)[None, :])\n",
    "# 对valid_len扩容\n",
    "print(valid_len.repeat_interleave(max_len)[:, None])\n",
    "mask = torch.arange(max_len)[None, :] < valid_len.repeat_interleave(max_len)[:, None]\n",
    "print(mask)\n",
    "print()\n",
    "\n",
    "# test\n",
    "Q, K, V = X, X, X\n",
    "score = torch.bmm(Q, K.permute(0, 2, 1)).reshape(-1, score.shape[-1])\n",
    "print(score, score.shape)\n",
    "\n",
    "print(score.masked_fill_(~mask, -1e6))\n",
    "F.softmax(score, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f92646-ba83-4d9d-8e3f-550f4bf50d62",
   "metadata": {},
   "source": [
    "#### 1.2 decoder_layer中的第一层self-attention\n",
    "例如序列长度为3, 最大长度为4，下三角矩阵:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 0 \\\\\n",
    "1 & 1 & 1 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "因为序列长度为3，实际的mask为:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "但这里其实没有必要，最后计算loss的时候会有一个loss掩码消除，后续会说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98a92f5d-6359-42a2-af6e-5ebf3a0acbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6611, 0.0600, 0.5174, 0.1596, 0.7550, 0.8390, 0.0674, 0.4631],\n",
      "         [0.1477, 0.3597, 0.9328, 0.0170, 0.9736, 0.4108, 0.8620, 0.8799],\n",
      "         [0.6569, 0.8152, 0.4810, 0.7388, 0.0312, 0.7049, 0.7364, 0.1079],\n",
      "         [0.1455, 0.2633, 0.9035, 0.6618, 0.9728, 0.9471, 0.8585, 0.9694]],\n",
      "\n",
      "        [[0.6430, 0.4919, 0.3397, 0.7519, 0.0770, 0.1563, 0.7086, 0.5063],\n",
      "         [0.2131, 0.3311, 0.7764, 0.2493, 0.1992, 0.9874, 0.2860, 0.0898],\n",
      "         [0.1783, 0.0602, 0.5747, 0.9875, 0.1572, 0.1534, 0.7301, 0.7916],\n",
      "         [0.6019, 0.7746, 0.4704, 0.7769, 0.8160, 0.4427, 0.1632, 0.6080]]]) torch.Size([2, 4, 8])\n",
      "tensor([3, 4]) torch.Size([2])\n",
      "\n",
      "tensor([1, 2, 3, 4, 1, 2, 3, 4])\n",
      "tensor([[ True, False, False, False],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [ True,  True,  True,  True],\n",
      "        [ True, False, False, False],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [ True,  True,  True,  True]])\n",
      "\n",
      "tensor([[ 2.2269e+00, -1.0000e+06, -1.0000e+06, -1.0000e+06],\n",
      "        [ 2.1499e+00,  3.6554e+00, -1.0000e+06, -1.0000e+06],\n",
      "        [ 1.5645e+00,  1.9012e+00,  2.9251e+00, -1.0000e+06],\n",
      "        [ 2.7211e+00,  3.8994e+00,  2.6685e+00,  4.8650e+00],\n",
      "        [ 2.1251e+00, -1.0000e+06, -1.0000e+06, -1.0000e+06],\n",
      "        [ 1.1689e+00,  1.9246e+00, -1.0000e+06, -1.0000e+06],\n",
      "        [ 2.0361e+00,  1.2130e+00,  2.5486e+00, -1.0000e+06],\n",
      "        [ 2.0676e+00,  1.6446e+00,  1.9881e+00,  3.0455e+00]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1816, 0.8184, 0.0000, 0.0000],\n",
       "        [0.1588, 0.2223, 0.6189, 0.0000],\n",
       "        [0.0728, 0.2366, 0.0691, 0.6214],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3196, 0.6804, 0.0000, 0.0000],\n",
       "        [0.3217, 0.1412, 0.5370, 0.0000],\n",
       "        [0.1909, 0.1251, 0.1764, 0.5076]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "torch.manual_seed(46)\n",
    "\"\"\"\n",
    "输入矩阵：\n",
    "    batch_size * max_seq_len * dim\n",
    "    batch_size=2, max_seq_len=4, dim=8\n",
    "有效长度矩阵：\n",
    "    batch_size *\n",
    "    batch_size=2\n",
    "\"\"\"\n",
    "X = torch.rand((2, 4, 8))\n",
    "valid_len = torch.randint(1, 5, (2, ))\n",
    "print(X, X.shape)\n",
    "print(valid_len, valid_len.shape)\n",
    "print()\n",
    "\n",
    "batch_size = X.shape[0]\n",
    "max_len = X.shape[1]\n",
    "dec_valid_len = torch.arange(1, max_len + 1).repeat(batch_size)\n",
    "print(dec_valid_len)\n",
    "mask = torch.arange(max_len)[None, :] < dec_valid_len[:, None]\n",
    "print(mask)\n",
    "print()\n",
    "\n",
    "# test\n",
    "Q, K, V = X, X, X\n",
    "score = torch.bmm(Q, K.permute(0, 2, 1)).reshape(-1, score.shape[-1])\n",
    "# print(score, score.shape)\n",
    "\n",
    "print(score.masked_fill_(~mask, -1e6))\n",
    "F.softmax(score, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa9f88-860d-48d8-8e63-a8fea432ef24",
   "metadata": {},
   "source": [
    "#### decoder输出掩码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "486c0467-2aa0-4a20-a844-9425906faa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6611, 0.0600, 0.5174, 0.1596, 0.7550, 0.8390, 0.0674, 0.4631],\n",
      "         [0.1477, 0.3597, 0.9328, 0.0170, 0.9736, 0.4108, 0.8620, 0.8799],\n",
      "         [0.6569, 0.8152, 0.4810, 0.7388, 0.0312, 0.7049, 0.7364, 0.1079],\n",
      "         [0.1455, 0.2633, 0.9035, 0.6618, 0.9728, 0.9471, 0.8585, 0.9694]],\n",
      "\n",
      "        [[0.6430, 0.4919, 0.3397, 0.7519, 0.0770, 0.1563, 0.7086, 0.5063],\n",
      "         [0.2131, 0.3311, 0.7764, 0.2493, 0.1992, 0.9874, 0.2860, 0.0898],\n",
      "         [0.1783, 0.0602, 0.5747, 0.9875, 0.1572, 0.1534, 0.7301, 0.7916],\n",
      "         [0.6019, 0.7746, 0.4704, 0.7769, 0.8160, 0.4427, 0.1632, 0.6080]]]) torch.Size([2, 4, 8])\n",
      "tensor([[2, 3, 1, 0],\n",
      "        [2, 3, 2, 1]]) torch.Size([2, 4])\n",
      "tensor([2, 4]) torch.Size([2])\n",
      "\n",
      "tensor([[2.0437, 2.6967, 1.8350, 2.6926],\n",
      "        [2.2255, 2.2697, 2.0158, 1.9066]])\n",
      "\n",
      "tensor([[ True,  True, False, False],\n",
      "        [ True,  True,  True,  True]])\n",
      "tensor([[2.0437, 2.6967, 0.0000, 0.0000],\n",
      "        [2.2255, 2.2697, 2.0158, 1.9066]]) tensor(1.6447)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "torch.manual_seed(46)\n",
    "\"\"\"\n",
    "输入矩阵：\n",
    "    batch_size * max_seq_len \n",
    "    batch_size=2, max_seq_len=4, dim=8\n",
    "有效长度矩阵：\n",
    "    batch_size *\n",
    "    batch_size=2\n",
    "\"\"\"\n",
    "y_hat = torch.rand((2, 4, 8))\n",
    "y = torch.randint(0, 4, (2, 4))\n",
    "out_valid_len = torch.randint(1, 5, (2, ))\n",
    "print(y_hat, y_hat.shape)\n",
    "print(y, y.shape)\n",
    "print(out_valid_len, out_valid_len.shape)\n",
    "print()\n",
    "\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "l = loss(y_hat.permute(0, 2, 1), y)\n",
    "print(l)\n",
    "print()\n",
    "\n",
    "max_len = y_hat.shape[1]\n",
    "mask = torch.arange(max_len)[None, :] < out_valid_len[:, None]\n",
    "print(mask)\n",
    "mask_one = torch.ones_like(y)\n",
    "mask_one[~mask] = 0\n",
    "l = l * mask_one\n",
    "print(l, l.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59058db4-a355-499b-bde4-2791fed428ac",
   "metadata": {},
   "source": [
    "#### 1.4 上述掩码整合并测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b0474-55a5-4a4e-98d2-17460d9b2d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
